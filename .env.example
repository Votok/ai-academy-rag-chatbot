# ============================================================================
# OpenAI API Configuration
# ============================================================================

# Required: Your OpenAI API key
# Get yours at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# GPT model for answer generation
# Options: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# Default: gpt-4
# GPT_MODEL=gpt-4

# Embedding model for vector generation
# Options: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
# Default: text-embedding-3-small
# EMBEDDING_MODEL=text-embedding-3-small

# Whisper model for audio transcription
# Default: whisper-1
# WHISPER_MODEL=whisper-1

# ============================================================================
# Directory Paths
# ============================================================================

# Directory containing source documents (PDFs and MP4 files)
# Default: ./data
# DATA_DIR=./data

# Directory for ChromaDB vector database storage
# Default: ./embeddings
# CHROMA_DB_DIR=./embeddings

# ============================================================================
# Text Processing Parameters
# ============================================================================

# Maximum size of text chunks for embedding (in characters)
# Larger chunks = more context but less precise retrieval
# Default: 1000
# CHUNK_SIZE=1000

# Number of characters to overlap between consecutive chunks
# Helps maintain context continuity across boundaries
# Default: 200
# CHUNK_OVERLAP=200

# ============================================================================
# Retrieval Parameters
# ============================================================================

# Number of most relevant chunks to retrieve for each query
# Higher values = more context but increased token usage
# Default: 5
# TOP_K=5
